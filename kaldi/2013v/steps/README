train_nnet_scheduler_angel-0.2_2gpu.sh：
这个脚本是为2gpu准备的，主要处理的是数据在内存中拷贝2份，分别给2块GPU去读，2份数据刚好是逆的，一个从数据头部读，一个从数据尾部读，当两者读到的数据和达到数据的长度时，说明一次iter结束。
目前该脚本支持2种形态的训练方法:
a. 2块gpu不需要在同一个pci总线上，即在bp的过程中一边反向传播，一边gpu之间传误差，且gpu传误差是通过cpu作为中间转换的(因为不在同一条总线上，gpu之间不能p2p), 将脚本中的变量train_tool改成###即可。
b. 2块gpu在同一条总线上，这样gpu之间传送数据就可以采用p2p的形式，速度比通过cpu传输要快。特别是针对k80GPU,它内部的2块gpu之间的p2p速度更快。所以此时采用的方案是等bp算完后gpu之间再互相传数据，将脚本中的变量train_tool改成###即可。

train_nnet_angel-0.2_2gpu.sh:
和脚本train_nnet_scheduler_angel-0.2_2gpu.sh配合使用的。

train_nnet_scheduler.sh：
这个就是kaldi自带的1块gpu训练脚本，用的是kaldi::nnet类。

train_nnet.sh：
和脚本train_nnet_scheduler.sh配合使用。

train_nnet_scheduler_angel-0.2_1gpu.sh：
该脚本主要是用1块gpu进行训练，只不过用的是angel-0.2里面实现的nnet方法，脚本内数据的准备形式和train_nnet_scheduler.sh中的一样，更改train_tool为###即可。
当然由于是用Angel-0.2代码实现的，而Angel-0.2里面带有bn层，所以该脚本可以使用bn算法进行训练。

train_nnet_angel-0.2_1gpu.sh：
和脚本train_nnet_scheduler_angel-0.2_1gpu.sh配合使用.


注：
1. 采用不同的策略(不同的模型，不同的gpu数量等)时，只需在调用train_nnet.sh上一层脚本改下调用目录即可，比如在myscript/train_dnn.sh中改
2. 其它没有在本文档中注释的脚本(除kaldi自带的脚本以外)可能是一些临时脚本，最好不要使用
